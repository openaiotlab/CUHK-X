<div align="center">

# ğŸ¯ CUHK-X Multi-Modal Action For Small Model Recognition

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![CUHK](https://img.shields.io/badge/CUHK-Research-purple.svg)](https://www.cuhk.edu.hk/)

**A comprehensive framework for multi-modal action recognition supporting RGB, Depth, Infrared, Thermal, Skeleton, Radar, and IMU data.**

[ğŸ“– Overview](#-overview) â€¢
[âœ¨ Features](#-features) â€¢
[ğŸš€ Quick Start](#-quick-start) â€¢
[ğŸ“ Dataset](#-dataset-preparation) â€¢
[ğŸ’» Usage](#-usage) â€¢
[ğŸ“§ Contact](#-contact)

</div>

---

## ğŸ“– Overview

This project provides a complete training pipeline for **multi-modal action recognition** models. It supports various data modalities and offers flexible data loading, preprocessing, training, and evaluation functionalities.

> ğŸ“¥ **Dataset Download**: [Coming Soon]

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ—ï¸ **Multiple Architectures** | ResNet (18/34/50), Vision Transformer (ViT) |
| ğŸ“Š **Multi-Modal Support** | RGB, Depth, Infrared, Thermal, Skeleton, Radar, IMU |
| âš–ï¸ **Class Imbalance Handling** | Optional oversampling for minority classes |
| ğŸ“ **Comprehensive Logging** | Detailed training process monitoring |
| ğŸ”€ **Flexible Data Splitting** | Cross-user and intra-split partitioning modes |
| ğŸ¯ **Contrastive Learning** | Support for self-supervised pre-training |

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- CUDA-compatible GPU (recommended)

### Installation

```bash
# Create conda environment
conda create -n cuhkx python=3.9
conda activate cuhkx

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ“ Dataset Preparation

Organize your dataset with the following structure:

```
dataset_root/
â”œâ”€â”€  RGB/
â”‚   â”œâ”€â”€  label1/
â”‚   â”‚   â”œâ”€â”€  user1/
â”‚   â”‚   â”‚   â”œâ”€â”€  sequence1/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€  image1.jpg
â”‚   â”‚   â”‚   â”‚   â””â”€â”€  image2.jpg
â”‚   â”‚   â”‚   â””â”€â”€  sequence2/
â”‚   â”‚   â””â”€â”€  user2/
â”‚   â””â”€â”€  label2/
â”œâ”€â”€  Depth/
â”œâ”€â”€  IR/
â”œâ”€â”€  Thermal/
â””â”€â”€ ...
```

> ğŸ’¡ **Note**: Labels correspond to action names.

---

## ğŸ’» Usage

### ğŸ¨ RGB / Depth / IR / Thermal Training

<details>
<summary><b>ğŸ”§ Option 1: Command Line</b></summary>

```bash
cd YOUR/PATH/rgb

python train_models_cross_multi.py \
  --dataset_root /path/to/dataset \
  --data rgb \
  --epochs 15 \
  --gpu 0 \
  --network resnet50 \
  --weights pretrained \
  --batch_size 64 \
  --learning_rate 0.001 \
  --split_mode intra \
  --labels "all" \
  --log_dir /path/to/log_dir \

```

</details>

<details>
<summary><b>ğŸ“œ Option 2: Shell Script</b></summary>

```bash
bash train_models_multi_intra.sh
```

</details>

#### ğŸ“‹ Parameter Reference

| Parameter | Description | Options |
|-----------|-------------|---------|
| `--dataset_root` | Root directory of the dataset | Path |
| `--data` | Data modality | `rgb`, `depth`, `ir`, `thermal` |
| `--epochs` | Number of training epochs | Integer (default: 15) |
| `--gpu` | GPU device number | Integer |
| `--network` | Network architecture | `resnet18`, `resnet34`, `resnet50`, `vit_b_16` |
| `--weights` | Weight initialization | `pretrained`, `scratch` |
| `--batch_size` | Batch size for training | Integer (default: 64) |
| `--learning_rate` | Learning rate | Float (default: 0.001) |
| `--split_mode` | Data splitting mode | `cross_subject`, `intra` |
| `--oversample` | Enable minority class oversampling | Flag |
| `--labels` | Label frequency rank range | String (e.g., "10,30") or "all" |
| `--cross_user_id` | Test user ID in cross_user mode | Integer |

---

### ğŸ¦´ Skeleton Cross_trail Training

```bash
cd skeleton

CUDA_VISIBLE_DEVICES=4,6 python train.py \
  --train_dir cross_trial_train.txt \
  --test_dir cross_trial_test.txt \
  --config ./configs/dstformer.yaml
```

> ğŸ“– See `skeleton/readme.md` for detailed configuration.

---

### ğŸ“¡ Radar Cross_trail Training

```bash
cd radar

bash ./train_radar_mix.sh
```


---

### ğŸ“± IMU Cross_trail Training

```bash
cd imu

bash ./command_accgyrmag_transformer_crosstrail.sh
```

> ğŸ“– See `imu/readme.md` for detailed configuration.

---

### cross-trail-remove long tail experiments

#### rgb
```bash
cd rgb 

python train_models_cross_multi.py \
  --dataset_root /path/to/dataset \
  --data rgb \
  --epochs 15 \
  --gpu 0 \
  --network resnet50 \
  --weights pretrained \
  --batch_size 64 \
  --learning_rate 0.001 \
  --split_mode intra \
  --oversample \
  --labels "10,30" \
  --log_dir /path/to/log_dir \
```

#### skeleton
```bash
cd skeleton

CUDA_VISIBLE_DEVICES=1,3 python train.py --train_dir cross_subject_train_top20_test1.txt --test_dir cross_subject_test_top20_test1.txt --config ./configs/dstformer.yaml
```

#### imu
```bash
cd imu

bash command_activity20_accgyrmag_resampling_crossuser.sh
```


### ğŸ¯ Cross-Subject Training (RGB)

```bash
cd rgb
cd cross_subject
```

| Script | Description |
|--------|-------------|
| `train_supervised_44.sh` | Fast baseline cross-subject training |
| `train_supervised_lt.sh` | Resampled cross-subject training |
| `train_contra_all_users_44.sh` | Contrastive learning (all actions) |
| `train_10_users_contra.sh` | Contrastive learning (resampled actions) |
| `train_10_users_contra_remove_env.sh` | Contrastive learning (without env variation) |

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ“§ Contact

<div align="center">

**For questions or suggestions, please contact:**

ğŸ“® **Email**: [syjiang@ie.cuhk.edu.hk](mailto:syjiang@ie.cuhk.edu.hk)

ğŸ« **The Chinese University of Hong Kong**

</div>

---

<div align="center">

â­ **If you find this project helpful, please consider giving it a star!** â­

</div>
